{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "8f1406d7-88da-4b46-a224-8ef7fcc82784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "#pd.set_option('display.max_columns', 500)\n",
    "import numpy as np\n",
    "import os\n",
    "from openpyxl import load_workbook\n",
    "import openpyxl \n",
    "import re\n",
    "#from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "0842cd8d-fd8c-4610-9189-8292e06ee0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to parent folder containing the folders with our data\n",
    "directory = r'C:\\Users\\jrbrz\\Desktop\\690\\assignments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "32cfd3cf-c80a-4217-87ad-d37acc5563a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### loop through the FAA data to merge it to a master df\n",
    "\n",
    "# the name of the folder the raw data files are in\n",
    "faaFolder = '\\\\FAAdataOriginal'\n",
    "#blank \"master\" df to append all files into for analysis\n",
    "faa = pd.DataFrame(columns = ['Date','Event','City','State'])# + list(range(0,27,1)))\n",
    "\n",
    "# looping through each raw file, cleaning up encoding issues \n",
    "# and appending it to the master df\n",
    "for entry in os.scandir(directory + faaFolder):\n",
    "    try:\n",
    "        # creating the file path\n",
    "        file = \"FAAdataOriginal\\\\\" + entry.name\n",
    "        \n",
    "        # loading the file into the openpyxl handler\n",
    "        wb = load_workbook(file)\n",
    "        \n",
    "        # grabbing actual worksheet name in the xlsx file\n",
    "        for s in range(len(wb.sheetnames)):\n",
    "            sheet = wb.sheetnames[s]\n",
    "            \n",
    "        # activating the worksheet    \n",
    "        ws = wb[sheet]\n",
    "        \n",
    "        # grabbing the data from the worksheet\n",
    "        data = ws.values\n",
    "        \n",
    "        # grabbing the column header names from the file\n",
    "        columns = next(data)[0:]\n",
    "        \n",
    "        # moving the data into a data frame\n",
    "        df = pd.DataFrame(data, columns=columns).iloc[:,0:4]\n",
    "        ### cleaning the Event text for encoding oddities\n",
    "        # strips the newline characters at the start of the strings\n",
    "        df['Event'] = df['Event'].apply(lambda x: x.strip())\n",
    "        # removes the ASCII character that is showing up\n",
    "        df['Event'] = df['Event'].apply(lambda x: x.replace(\"_x000D_\",\"\"))\n",
    "        # removes double \\n characters to make cleaner splitting below in the next step\n",
    "        df['Event'] = df['Event'].apply(lambda x: x.replace(\"\\n\\n\",\"\\n\"))\n",
    "        df['Event'] = df['Event'].apply(lambda x: x.replace(\"\\n\\n\\n\",\"\\n\"))\n",
    "        df['Event'] = df['Event'].apply(lambda x: x.replace(\"\\n\\n\\n\\n\",\"\\n\"))\n",
    "        \n",
    "        # parsing out the Event text string into separate data fields\n",
    "        ##temp = df['Event'].apply(lambda x: pd.Series(str(x).split(\"\\n\")))\n",
    "        \n",
    "        # joining the separated \n",
    "        ##df = df.join(temp)\n",
    "        \n",
    "        #added the df from each individual file into the master df\n",
    "        faa = faa.append(df, ignore_index=True).fillna(np.NaN)\n",
    "        \n",
    "        \n",
    "    except:\n",
    "        # same work flow as the loop above but customize for a couple files that \n",
    "        # would not work with all of the steps above. The removed steps are commented\n",
    "        # out below.\n",
    "        try:\n",
    "            file = \"FAAdataOriginal\\\\\" + entry.name\n",
    "            wb = load_workbook(file)\n",
    "            for s in range(len(wb.sheetnames)):\n",
    "                sheet = wb.sheetnames[s]\n",
    "            ws = wb[sheet]\n",
    "            data = ws.values\n",
    "            columns = next(data)[0:]\n",
    "            df = pd.DataFrame(data, columns=columns).iloc[:,0:4]\n",
    "            \n",
    "            df['Event'] = df['Event'][0].replace(\"_x000D_\",\"\")\n",
    "            df['Event'] = df['Event'].apply(lambda x: x.replace(\"\\n\\n\",\"\\n\"))\n",
    "            df['Event'] = df['Event'].apply(lambda x: x.replace(\"\\n\\n\\n\",\"\\n\"))\n",
    "            df['Event'] = df['Event'].apply(lambda x: x.replace(\"\\n\\n\\n\\n\",\"\\n\"))\n",
    "            df['Event'] = df['Event'][0].replace(\" \\n\\n\\n\",\"\\n\")\n",
    "                        \n",
    "            ##temp = df['Event'].apply(lambda x: pd.Series(str(x).split(\"\\n\")))\n",
    "            ##df = df.join(temp)\n",
    "            faa = faa.append(df, ignore_index=True).fillna(np.NaN)\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            print(entry.name)\n",
    "del faa['Day of Sighting']\n",
    "faa.to_csv(\"faa_data.csv\")\n",
    "\n",
    "\n",
    "# this section is to organize all of the similar categories into their own columns\n",
    "# this splits the text strings based on the category list variable directly below\n",
    "categories = ['UAS MOR Alert for ', 'Number:', 'Type:', 'Date/Time:',\n",
    "              'A/C:', 'Summary:']\n",
    "\n",
    "for j in range(len(categories)):\n",
    "    if categories[j] == 'UAS MOR Alert for ':\n",
    "        faa[\"PRELIM\"] = faa[\"Event\"].apply(lambda x: re.split(categories[j] , x)[0].replace('PRELIM INFO FROM FAA OPS:', \"\"))\n",
    "\n",
    "    elif categories[j] == 'Summary:':\n",
    "        \n",
    "        faa[\"SUMMARY\"] = faa[\"Event\"].apply(lambda x: re.split(categories[j],x)[1] if len(re.split(categories[j],x))>1 else np.NaN)\n",
    "        \n",
    "    else:\n",
    "        #re.search(r'UAS MOR Alert for (.*?)\\nNumber:', event).group(1)\n",
    "        faa[categories[j-1]] = faa[\"Event\"].apply(lambda x: re.search(r''+categories[j-1]+r\"(.*?)\\n\"+categories[j],x).group(1) if re.search(r''+categories[j-1]+r\"(.*?)\\n\"+categories[j],x) else np.NaN)\n",
    "\n",
    "faa.to_csv(\"UAS_initialSplit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "fc32b6ff-f85c-41ee-8cad-8b51eb587138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop for the ASRS data to merge all files\n",
    "asrsFolder = '\\\\ASRSdata'\n",
    "asrs = pd.DataFrame()\n",
    "for entry in os.scandir(directory + asrsFolder):\n",
    "    temp = pd.read_csv(entry.path)\n",
    "    asrs = asrs.append(temp)\n",
    "asrs.to_csv(\"asrs_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497e4cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
